{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing the Build/Train/Deploy MLOps Project Template\n",
    "\n",
    "We recently announced [Amazon SageMaker Pipelines](https://aws.amazon.com/sagemaker/pipelines/), the first \n",
    "purpose-built, easy-to-use Continuous Integration and Continuous Delivery (CI/CD) service for machine learning. \n",
    "SageMaker Pipelines has three main components which improves the operational resilience and reproducibility of your \n",
    "workflows: Pipelines, Model Registry, and Projects. \n",
    "\n",
    "SageMaker Projects introduce MLOps templates that automatically provision the underlying resources needed to enable \n",
    "CI/CD capabilities for your Machine Learning Development Lifecycle (MLDC). Customers can use a number of built-in \n",
    "templates or create your own custom templates.\n",
    "\n",
    "This example will focus on using one of the MLOps templates to bootstrap your ML project and establish a CI/CD \n",
    "pattern from seed code. We’ll show how to use the built-in Build/Train/Deploy Project template as a base for a \n",
    "customer churn classification example. This base template will enable CI/CD for training machine learning models, \n",
    "registering model artifacts to the Model Registry, and automating model deployment with manual approval and automated \n",
    "testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLOps Template for Build, Train, and Deploy\n",
    "\n",
    "We’ll start by taking a detailed look at what AWS services are launched when this build, train, deploy MLOps template \n",
    "is launched. Later, we’ll discuss how the skeleton can be modified for a custom use case. \n",
    "\n",
    "To get started with SageMaker Projects, [they must be first enabled in the SageMaker Studio console](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-studio-updates.html). \n",
    "This can be done for existing users or while creating new ones:\n",
    "\n",
    "<img src=\"img/enable_projects.png\">\n",
    "\n",
    "Within Amazon SageMaker Studio, you can now select “Projects” from a drop-down menu on the “Components and registries” \n",
    "tab as shown below:\n",
    "\n",
    "<img src=\"img/select_projects.png\">\n",
    "\n",
    "From the projects page you’ll have the option to launch a pre-configured SageMaker MLOps template. We'll select the build, train and deploy template:\n",
    "\n",
    "<img src=\"img/create_project.png\">\n",
    "\n",
    "NOTE: Launching this template will kick off a model building pipeline by default and will train a regression model. This will incur a small cost.\n",
    "\n",
    "Once the project is created from the MLOps template, the following architecture will be deployed:\n",
    "\n",
    "<img src=\"img/deep_dive.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the Seed Code for Custom Use Case\n",
    "\n",
    "After your project has been created the architecture shown above will be deployed and the visualization of the \n",
    "Pipeline will be available in the “Pipelines” drop down menu within SageMaker Studio.\n",
    "\n",
    "In order to modify the seed code from this launched template, we’ll first need to clone the AWS CodeCommit \n",
    "repositories to our local SageMaker Studio instance. From the list of projects, select the one that was just \n",
    "created. Under the “Repositories” tab you can select the hyperlinks to locally clone the AWS CodeCommit repos:\n",
    "\n",
    "<img src=\"img/clone_repos.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelBuild Repo\n",
    "\n",
    "The SageMaker project template will create this repositories.\n",
    "\n",
    "In the `...-modelbuild` repository there's the code for preprocessing, training, and evaluating the model. \n",
    "The seed code trains and evaluates a model on the [UCI Abalone dataset](https://archive.ics.uci.edu/ml/datasets/abalone):\n",
    "\n",
    "<img src=\"img/repo_directory.png\">\n",
    "\n",
    "\n",
    "**In our case we want to create a pipeline for predicting Churn (part 1 of the lab).** We can modify these files in order to solve our own customer churn use-case.\n",
    "\n",
    "\n",
    "We’ll need a dataset accessible to the project (_Churn dataset_). \n",
    "\n",
    "The easiest way to do this is run the following in our notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "```\n",
    "!wget http://dataminingconsultant.com/DKD2e_data_sets.zip\n",
    "!unzip -o DKD2e_data_sets.zip\n",
    "!mv \"Data sets\" Datasets\n",
    "```\n",
    "\n",
    "```\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "prefix = 'sagemaker/DEMO-xgboost-churn'\n",
    "region = boto3.Session().region_name\n",
    "default_bucket = sagemaker.session.Session().default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "RawData = boto3.Session().resource('s3')\\\n",
    ".Bucket(default_bucket).Object(os.path.join(prefix, 'data/RawData.csv'))\\\n",
    ".upload_file('./Datasets/churn.txt')\n",
    "\n",
    "print(os.path.join(\"s3://\",default_bucket, prefix, 'data/RawData.csv'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ok, now we have donwloaded the Churn dataset and uploaded it to our S3 Bucket that is accessible to the SageMaker Project role.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "### Modifying the code for the Churn problem\n",
    "\n",
    "This is the sample structure of the Project (Abalone):\n",
    "\n",
    "<img src=\"img/repo_directory.png\">\n",
    "\n",
    "\n",
    "#### We'll need to:\n",
    "1. rename the `abalone` directory to `customer_churn`\n",
    "2. replace `codebuild-buildspec.yml` in your current Studio project (Abalone) with the one found in [modelbuild/codebuild-buildspec.yml](modelbuild/codebuild-buildspec.yml) (Churn)\n",
    "3. replace the `preprocess.py`, `evaluate.py` (of the sample Abalone) with the ones found in `modelbuild/pipelines/customer_churn`\n",
    "4. replace `pipeline.py`(Abalone) with the one found in `modelbuild/pipelines/customer_churn/pipeline.py`\n",
    "\n",
    "    \n",
    "5. **In the `pipeline.py` file you'll need to replace the `default_value` of `InputDataURL` with the URL you obtained when uploading the data above.**\n",
    "    \n",
    "```python\n",
    "#in pipeline.py\n",
    "...\n",
    "input_data = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value=f\"s3://EXAMPLE-BUCKET/PATH/TO/RawData.csv\",  # Change this to point to the s3 location of your raw input data.\n",
    ")\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger a new training Pipeline Execution through git commit\n",
    "\n",
    "By committing these changes to the AWS CodeCommit repository (easily done in SageMaker Studio source control tab), a \n",
    "new Pipeline execution will be triggered since there is an EventBridge monitoring for commits.  After a few moments, \n",
    "we can monitor the execution by selecting your Pipeline inside of the SageMaker Project.\n",
    "\n",
    "<img src=\"img/git_push.png\">\n",
    "\n",
    "This triggers the pipelines for training. Go to our `“Pipelines”` tab inside of the SageMaker Project. Click on our only pipeline. And you'll see:\n",
    "\n",
    "<img src=\"img/execute_pipeline.png\">\n",
    "\n",
    "Select the most recent execution:\n",
    "\n",
    "<img src=\"img/dag.png\">\n",
    "\n",
    "\n",
    "## Trigger the ModelDeploy Pipeline\n",
    "\n",
    "Once the train pipeline is completed, we can go to our `“Model groups”` tab inside of the SageMaker Project and inspect the metadata attached to the model artifacts. If everything looks good, we can manually approve the model:\n",
    "\n",
    "<img src=\"img/model_metrics.png\">\n",
    "\n",
    "<img src=\"img/approve_model.png\">\n",
    "\n",
    "This approval will trigger the ModelDeploy pipeline (in CodePipeline):\n",
    "\n",
    "<img src=\"img/execute_pipeline_deploy.png\">\n",
    "\n",
    "After we deploy to a staging environment and run some tests, we will have to **approve the deployment to production** by approving in the `ApproveDeployment` stage:\n",
    "\n",
    "<img src=\"img/approve_deploy_prod.png\">\n",
    "\n",
    "\n",
    "\n",
    "Finally, if we go back to Studio, we will see the Production endpoint for real time inference.\n",
    "\n",
    "<img src=\"img/endpoints.png\">"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
